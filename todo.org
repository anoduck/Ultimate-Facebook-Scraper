#+TITLE: TODO DOT ORG
#+DATE: 04-26-2021
#+AUTHOR: anoduck
#+EMAIL: anoduck@github.com
#+CATEGORY: Tasks
#+PROJECT: ORG
# ===============================================================================

* Tasks earlier development
** DONE Successfully scrape images and albums
*** DONE [#A] Finish setting up gender filtering
  	- [x] Write Function
  	- [x] integrate into scrypt
  	- [ ] Test functionality
*** DONE [#B] Find means to mitigate error of no attribute in next page functions.
*** CANCELED [#B] Rewrite scrap_profile function
  	- [ ] combine this with the scraper_control
	- [ ] rearrage flow of script to fully complete one user at a time
*** DONE [#B] create function for album walkthrough to reduce size of code.
  	- [x] create independent function
  	- [x] remove redundancy
*** DONE [#A] Find a solution to the infinite page loop dilemna
*** DONE [#A] Find solution for locating individual image links from thumbnail page
  	- [x] I totally have no idea what is preventing this from success
  	- [x] I added a line to print the link it is scraping, which it skips everytime.
*** DONE [#A] Find solution for stale element exception that is plagueing the script currently.
*** DONE [#A] Troubleshoot new error of elements "temporarily unable to be viewed"
*** DONE [#B] Combine `get_fullphoto()` with gallery_walker
*** DONE [#B] rewrite gallery_walker to walk gallery pages not images
*** DONE [#B] Control which ID gets scraped
*** DONE Scrape albums
** DONE Scrape Friends
** DONE Scrape Based on genders
** TODO Setup config.py for easier configuration by users
  Why am I doing this? I do not know...
** DONE Remove useless, broken, and unused bits of code.
* TODO Later stage developement
** TODO Setup config.py for easier configuration
** TODO move from username to userid
** TODO Correct failed creation of folder hierarchy
*** TODO link call to ensure folder structure with userid.
* Docs
  - https://www.scrapingbee.com/blog/web-scraping-without-getting-blocked/
  - https://selenium-python.readthedocs.io/